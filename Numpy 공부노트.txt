-넘파이는 파이썬의 모듈 중 하나이며 numerical python의 약자

-파이썬에서 넘파이를 쓰고 싶을 때는 import numpy as np. np는 사실 다른걸로 써도 상관없다. 내 코드 상에서 넘파이를 뭐라고 지칭할 지 정하는 것

-넘파이는 array라는 data structure를 사용하는데, 리스트의 일환이고 좀 더 특이하다(?) 고 일단 생각하면 된다. 안에 담기는 정보는 str, int, float, 심지어 다른 array까지 가능하다. 

-일반적인 list 타입을 np.array(리스트)를 통해서 넘파이 어레이로 바꿀 수 있다. 출력하면 리스트와는 다르게 ,콤마 없이 출력된다. 

-csv 파일에서 바로 가져올 때는 np.genfromtxt('csvname.csv', delimiter=',') (제너레이트 프롬 텍스트) 로 가져온다.

-리스트 대신 넘파이 어레이를 쓰는 이유는 데이터 수정 과정이 훨씬 편리하기 때문. 넘파이 어레이는 마치 int 한개를 다루는 것 마냥 코드를 짤 수 있다. 예를 들어 기존의 리스트 값들보다 3 커진 리스트를 만들고 싶을 때 리스트는,
l = [1, 2, 3, 4, 5]
l_plus_3 = []
for i in range(len(l)):
    l_plus_3.append(l[i] + 3)
이렇게 안의 element들에 접근하기 위해 for loop를 사용해야 하지만 넘파이 어레이는
a = np.array(l)
a_plus_3 = a + 3
그냥 int 처럼 다룬다. 넘나 간단쓰! 다른 이항연산에 대해서도 마찬가지 제곱이나 제곱근도 가능하다. 
>>> a ** 2
array([ 1,  4,  9, 16, 25, 36])
>>> np.sqrt(a)
array([ 1, 1.41421356, 1.73205081, 2, 2.23606798, 2.44948974])

-리스트로 이루어진 리스트가 가능한 것처럼, 어레이로 이루어진 어레이도 가능하다. 그 중에서도 모든 element array가 같은 크기일 경우(안의 엘리먼트 갯수가 같은 것) 이것을 two-dimensional array 라고 한다.  (위에서 쓴 가장 기본적인 array은 one-dimensional) 작업 시 당연히 어레이들을 []대괄호로 한번 더 감싸줘야한다. 
-two dimensional에서도 그냥 + 3 하면 모든 엘리먼트에 더해준다;; 편리함 무엇..

-indexing이나 element selection은 리스트와 방식이 똑같고 여러개의 엘리먼트를 뽑아내는 경우 어레이 타입으로 나오게 된다.
-two-dimensional 에서는 어떻게 선택할까? 매트릭스에서 위치 잡는 것과 똑같다(0부터 시작하는 것만 유의) 즉 array[1,3]하면 두번째 행 네번째 열 엘리먼트를 선택하는 것. 당연히 범위도 가능하며 전체를 선택하고 싶을 때는 [:,2] 식으로 해주면 된다(세번째 컬럼 전체를 선택하는 코드) 근데 컬럼은 axis0이고 row(array)는 axis1 이라고 말하는데 이러면 판다스랑 정반대인데...ㅠㅠㅠ 머징 너무 헷갈리잖아. 둘 중에 하나가 잘못된건지 뭔지는 모르겠는데 어쨌든 판다스와는 다르게 넘파이에서는 axis를 명시적으로 적어야할 일은 없는 것 같긴 함ㅠㅠ
-이미 two dimensional인데 첫번째 줄, 즉 첫번째 요소(어레이)만 가져가고 싶다고 array[0]은 안되는 듯... 아니네 되네 편리함 어쩔거...;; 근데 코드 읽는 사람이 헷갈릴 순 있겠다. 이게 row 선택한겨 column 선택한겨 하고


-logical operation 도 간단히 가능
a = np.array([10, 2, 2, 4, 5, 3, 9, 8, 9, 7])
a > 5 라고 적으면 
array([True, False, False, False, False, False, True, True, True, True], dtype=bool) 이런 어레이가 나온다고? 함. for loop 사용할 필요 없다. 
a[a > 5]
array([10, 9, 8, 9, 7]) 요런식으로 판다스와 비슷하게 selection 가능하다. 당연히 & | 사용가능 
조건으로 선택하면 당연히 행렬 형식이 아니라 원디멘셔널로 나온다. 또한 컬럼으로 한줄을 선택해도 가로의 어레이가 나옴



statistics
-np.mean(), median(), percentile() 등 기본적인 통계를 확인할 수 있다. 

-괄호 안에 logical operation 을 활용하는 것도 된다. np.mean(survey_array > 8) 이런식으로~ 오잉! 근데 8이 넘는 값들의 평균을 내주는게 아니다?? 설명에 따르면 survey_array > 8이라는 logical statement가 8을 넘는 애들한테 value 1을 부여하는 것까지 한다고 한다. 그래서 mean은 이 1들을 다 더한 뒤 survey_array 전체 '길이'로 나눈다고... 그래서 산출되는 값은 전체 요소 중 8이 넘는 애들의 비율이라고 한다. mean이 어떻게 알고 갑자기 value 값의 합 대신 value 갯수로 전환한거지?? 띠용띠용.. 참고로 그냥 np.mean(survey_array) 로 하면 평균값(average)이 나온다. 

- two dimensional 에서는 어떻게 mean을 계산할까? 아무것도 없이 어레이 이름만 넣으면 다아아아 더해서 전체 갯수로 나눈다. 즉 딱 한개의 값만 산출된다. 어레이 뒤에 키워드 axis = 1 을 넣어주면 row별로 계산하기 때문에 (왜 판다스랑 반대...) row 갯수만큼 one-dimensional array로 출력된다. axis =0은 컬럼별로 계산해서 컬럼 갯수만큼!

-다른 value들과 이상하게 너무 차이나서 mean 등의 수치에 영향을 주는 애들을 outlier 아웃라이어라고 한다. 이런 애들은 실수로 잘못 입력된 애일 수 있고(이러면 mean 등이 제대로 된 값이 아니게 되니까 찾아서 수정해야겠지), 아니면 잘못된 게 아니라 정말 유달리 크거나 작은 애일 수 있다. (이러면 고칠 필요는 없지만 주의깊게 살펴봐야겠지) 

-아웃라이어를 찾아내는 한가지 방법은 np.sort()를 이용하는 것이다. 정렬해서 우리의 예상치를 이상하게 벗어난 값이 있는지 맨 앞과 맨 뒤를 본다. sort에 아무 키워드 없이 어레이만 넣으면 올림차순으로 정렬된다.   

-np.median()은 어레이의 중간값을 내준다. 만약 엘리먼트가 짝수 개수면 가운데 두개의 평균을 내준다. 

-mean은 outlier에 의해 영향을 받는 반면 median은 그렇지 않다. median 도 한두칸 옯겨갈테니 영향을 받는거 아니냐 할 수도 있겠지만 데이터 셋의 크기가 커질수록 아웃라이어의 영향력은 0에 수렴한다. 

-meadian(중간값)은 50퍼센트 백분위이기도 하다. 50퍼센트는 메디안의 밑에 있고 50퍼센트는 위에 있다. Nth percentile이라는 건 밑에 N퍼센트가 있다는 얘기이다. 25퍼센틸은 25퍼센트가 밑에 있고 75프로가 위에 있다는 얘기이다. 그럼 하위 75프로와 같다는 것인듯?

-np.percentile 이라는 메소드가 따로 있다. np.percentile(array, percentile) 형식으로 쓴다. 

-일부 퍼센틸은 이름이 따로있다. 25, 50, 75는 순서대로 first quartile, median, third quartile 이라고 한다. min과 max까지 합쳐서 five-number summary라고 부른다. 75퍼센틸 - 25퍼센틸을 interquartile range라고 하는데, 데이터의 50퍼센트는 이  interquartile range 사이에 있다는 얘기가 된다. 이걸 보면 data가 얼마나 분산되어 있는지 확인할 수 있다. interquartile range가 작을수록 variance가 작다는 말이 된다(모여있다는 뜻)

-standard deviation 은 interquartile range와 비슷하게 데이터들이 어떻게 분포해있는지 보여준다. 즉 평균이 같아도 디비에이션이 0 이면 전부 같은 값(평균값)이라는 것이고 디비에이션이 크면 평균을 기준으로 굉장히 작은값과 큰값까지 퍼져있다는 얘기이다. 스탠다드 디비에이션은 np.std() 형식으로 쓴다. 





histrogram & prediction
-가장 기본적인 히스토그램은 아무래도 각 value가 몇개씩 들어있는지 보여주는 bar graph 이겠다. 데이터가 늘어나면 한개의 value 갯수를 따지기 보다는 범위 당 갯수를 따지기 마련이다 (0-5는 몇개, 5-10은 몇개 이런식으로) 이런 grouping을 'bins' 라고 부른다. 당연하지만 모든 bin은 항상 같은 사이즈여야 한다. bin의 범위, 즉 빈내에서 max-min은 bin의 width라고 부른다. 

-matplotlib을 이용해서 히스토그램을 만들거다. matplotlib에 대해서 배우는건 다음 코스에서 하고, 지금은 아주 간단한 코드들만 쓸거다. 

-불러올때는 from matplotlib import pyplot as plt
 
-histogram을 만들때는 plt.hist(데이터) 형식을 사용한다. 아무 키워드를 넣지않으면 데이터 전체를 10등분해서 출력한다. 갯수를 조정하고 싶으면 bins =5 식으로 키워드를 넣어주자. 다른 범위를 사용하고 싶으면(데이터의 min과 max가 range의 양끝이 아니라 다른범위) range = (min, max) 키워드를 넣어주면 된다. range이므로 max의 바로 앞까지다. 50까지 넣고 싶으면 max는 51로 설정해주자. (그래프에는 51까지 포함하는 것처럼 보이는데..?)

-그래프를 출력하고 싶을때는 print() 대신 plt.show()를 사용한다. (괄호 안에 아무것도 안넣는듯?)

-그래프에 따라서 데이터셋을 분류하는 한가지 방법은 peak를 따지는 것이다. peak가 한개인 경우(정규분포처럼) unimodal distribution이라고 하고 두개면 bimodal, 그 이상은 multimodal distribution, 그리고 딱히 peak가 없는 그래프라면(다 고만고만한경우) uniform distribution이라고 한다. 

-우리가 다룰 데이터셋은 많은 경우에 unimodal이다. unimodal을 좀 더 자세히 분류해보자. symmetric은 가운데가 봉긋하게 솟아있는 데이터셋. 한쪽으로 치우쳐져있지 않다. skew-right는 peak가 왼쪽으로 치우친 데이터셋이다. 오른쪽으로 긴 꼬리를 가지기 때문에 right를 쓰는 듯하다. 헷갈리지 말기. skew-left는 peak가 오른쪽으로 치우쳐서 왼쪽으로 긴 꼬리를 가지고 있는 데이터셋. symmetric인 경우 mean 과 median이 유사하며, skew-right는 mean이 median보다 오른쪽에 있다. median은 비교적 peak를 따라가고 mean은 가장 오른쪽의 극단적인 데이터들에 영향을 받기 때문. 받대로 skew-left는 mean이 더 왼쪽에 있다. skew 정도가 심할수록 mean이 less useful 해진다. 


-자, 이제 다른 얘기. 통계에서 가장 기본이 되는 분포는 normal distribution(정규분포)이다(symmetric이고 unimodal). 국민키, 혈압 등 많은 것들이 정규분포 형태를 보인다. 정규분포는 두가지 요소에 의해 결정되는데 첫번째는 평균(median 아니다 유의!)이고 두번째는 standard deviation이다. mean이 가운데 위치를 정하고 스탠다드 디비에이션이 너비를 정한다. 즉 디비에이션이 작으면 그래프가 좁고 높은 형태를 띄고 디비에이션이 크면 그래프가 낮고 넓은 형태를 보인다. 즉, 같은 unimodal symmetric shape이더라도 세부 모양이 달라진다. 

-넘파이에는 정규분포에 맞춰서 random number를 만들어주는 generator가 있다. np.random.normal() 형식을 사용하며, 괄호안에는 세가지 키워드가 들어간다. loc: 정규분포의 mean, scale: std, size: 만들 랜넘넘버의 개수. 키워드 이름없이 그냥 a = np.random.normal(0, 1, size=100000) 식으로 써도 되는 듯

-정규분포에서 mean과 std의 값에 상관없이 항상 성립하는 규칙이 있는데 mean 플마 std 의 범위에 68%의 데이터 셋이 속해있다는 것이다. 즉 mean이 0이고 std가 10이면 -10부터 10 사이에 전체 데이터셋의 68프로가 위치한다. +- 2std는 95프로고 +- 3std는 99.7프로이다. 물론 약간의 오차는 있다. 코드카데이에 있는거 돌려보니까 67 ~ 69를 왔다갔다 하더라. 어쨌든 요걸 within one standard deviation of the mean 이라고 부른다.


binomial distribution
-주어진 정보들로 probability를 예측하는 것?

-넘파이의 random number generator로 요것을 할 수 있다고 함. np.random.binomial() 이라는 함수를 쓴다고. 세개의 argument를 넣어줘야 하는데 N: number of samples/trials P: probability of success, size: number of experiments

-예를 들어 한 농구선수가 10번의 자유투 중 3번 성공할 확률을 예측하고 싶다고 해보자. N은 10 P는 0.3이 된다. 그리고 size는 10000번으로 설정한다면 컴퓨터는 10000번 실험(experiment)을 돌린다. 즉, 농구선수의 자유투 확률이 0.3인데 실제로 10번 던지면 무조건 딱 3번만 넣을까? 사실 그렇지 않다. 아마 한번의 자유투당 0.3으로 각각 독립사건으로 계산하겠지. 컴퓨터는 우리가 설정한 사이즈만큼 돌려보고 기록한다. 첫번째 실험에서는 4번 성공 두번째 실험에서는 3번 성공 ... 이런식으로. 그리고 10000번의 결과에 대해서 plot하면 아마 mean이 3에 아주 가까운(사이즈가 클수록 3에 수렴하는) unimodal graph일 것이다. 정규분포는 아닐듯, 아마 symmetric이 아닐테니. 요로케 해서 그래프를 보면 지금 10회 던지는데 3번,4번,5번 성공할 확률이 얼마일지 알 수 있다.
기본 코드는 a = np.random.binomial(10, 0.30, size=10000) 형식이다. 실제로 돌려보는거니 그래프의 세부수치는 돌릴 때마다 살짝 달라질 것이다. 전체적인 모양은 유지하겠지만.

-그리고 그래프를 살펴보는게 아니라 직접 수치를 얻고 싶다면, 즉 4번 넣을 확률만 딱! 알고 싶으면 np.mean()을 통해서 ㅎ할 수 있다. logical statement가 들어간 mean은 평균이 아니라 전체 value 대비 조건을 만족하는 value의 비율을 출력한다는 것을 잊지 말자. 
a = np.random.binomial(10, 0.30, size=10000)
np.mean(a == 4) -> 확률 0.4가 아니라 횟수 4인 것에 유의
이런 형식으로 사용한다. 그래프 자체를 variable에 할당한 것을 볼 수 있다. 



















